{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b064c456-f133-42bf-8534-b36e5e59f1fb",
   "metadata": {},
   "source": [
    "### 2.2.2 对称动态量化代码实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085a3708-6a12-4ef9-a3d4-fd6fc879f6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原参数: tensor([[ 0.1234,  0.5678,  0.9012],\n",
      "        [-0.2468, -0.1357,  0.3579]])\n",
      "量化后(int8): tensor([[ 17,  80, 127],\n",
      "        [-35, -19,  51]], dtype=torch.int8)\n",
      "反量化后: tensor([[ 0.1202,  0.5655,  0.8977],\n",
      "        [-0.2474, -0.1343,  0.3605]])\n",
      "量化参数 - scale: 0.007068, zero_point: 0\n",
      "\n",
      "浮点模型输出: tensor([[0.7683, 0.3561]], grad_fn=<MmBackward0>)\n",
      "量化模型输出: tensor([[0.7778, 0.3560]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建简单模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 2, bias=False)\n",
    "        # 设置固定权重便于观察\n",
    "        self.linear.weight.data = torch.tensor(\n",
    "            [[0.1234, 0.5678, 0.9012],\n",
    "             [-0.2468, -0.1357, 0.3579]],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleModel()\n",
    "\n",
    "# 获取第一个权重的原始参数\n",
    "original_param = model.linear.weight.data\n",
    "print(f\"原参数: {original_param}\")\n",
    "\n",
    "# 动态量化\n",
    "# torch.ao.quantization.quantize_dynamic 参数详解:\n",
    "# 1. model: 要进行量化的模型\n",
    "# 2. {nn.Linear}: 指定要量化的模块类型集合(这里只量化Linear层)\n",
    "# 3. dtype: 量化数据类型(torch.qint8表示8位有符号整数)\n",
    "# 返回值: 量化后的模型(只有指定模块被量化，其他保持不变)\n",
    "model_int8 = torch.ao.quantization.quantize_dynamic(\n",
    "    model,\n",
    "    {nn.Linear},\n",
    "    dtype=torch.qint8 # 8位有符号整数（默认）\n",
    ")\n",
    "\n",
    "# 获取量化参数\n",
    "# 重要: 量化后，model_int8.linear.weight 不再是一个属性，而是一个函数!\n",
    "# 调用 weight() 返回 PackedParams 对象\n",
    "quantized_weight_all = model_int8.linear.weight()\n",
    "\n",
    "# 正确获取参数的方法:\n",
    "# 1. 获取反量化后的浮点参数(用于计算)\n",
    "dequantized_param = quantized_weight_all.dequantize()\n",
    "\n",
    "# 2. 获取int8表示(实际存储的量化值)\n",
    "int8_param = quantized_weight_all.int_repr()\n",
    "\n",
    "# 3. 获取量化参数\n",
    "# q_scale: 量化缩放因子，用于将浮点数映射到整数范围\n",
    "# q_zero_point: 零点偏移，表示浮点0对应的整数值\n",
    "print(f\"量化后(int8): {int8_param}\")\n",
    "print(f\"反量化后: {dequantized_param}\")\n",
    "print(f\"量化参数 - scale: {quantized_weight_all.q_scale():.6f}, zero_point: {quantized_weight_all.q_zero_point()}\")\n",
    "\n",
    "# 测试推理\n",
    "test_input = torch.randn(1, 3)\n",
    "output_fp32 = model(test_input)\n",
    "output_int8 = model_int8(test_input)\n",
    "print(f\"\\n浮点模型输出: {output_fp32}\")\n",
    "print(f\"量化模型输出: {output_int8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4585e-c695-4044-bdb6-6f1369481f75",
   "metadata": {},
   "source": [
    "### 3.2.2 对称静态量化代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf926ee4-be78-49b1-815b-c940916f4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点模型输出:\n",
      "tensor([[0.1677, 0.2300]], grad_fn=<MmBackward0>)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/quantization/lib/python3.12/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "linear1 原始FP32权重:\n",
      "tensor([[ 0.1234,  0.5678,  0.9012],\n",
      "        [-0.2468, -0.1357,  0.3579],\n",
      "        [ 0.4680,  0.7890, -0.1011],\n",
      "        [-0.3234,  0.6543, -0.9876]])\n",
      "\n",
      "linear1 按通道量化INT8权重:\n",
      "tensor([[  17,   80,  127],\n",
      "        [ -88,  -48,  127],\n",
      "        [  76,  127,  -16],\n",
      "        [ -42,   84, -128]], dtype=torch.int8)\n",
      "\n",
      "linear1 反量化FP32权重:\n",
      "tensor([[ 0.1202,  0.5655,  0.8977],\n",
      "        [-0.2470, -0.1347,  0.3565],\n",
      "        [ 0.4703,  0.7859, -0.0990],\n",
      "        [-0.3253,  0.6507, -0.9915]])\n",
      "\n",
      "linear1 按通道量化参数（4个通道）:\n",
      "  通道0 - scale: 0.007068, zero_point: 0\n",
      "  通道1 - scale: 0.002807, zero_point: 0\n",
      "  通道2 - scale: 0.006188, zero_point: 0\n",
      "  通道3 - scale: 0.007746, zero_point: 0\n",
      "  通道维度: axis=0（0=输出特征维度）\n",
      "\n",
      "激活量化参数（按张量） - scale: 0.030678, zero_point: 55\n",
      "  说明：激活无多通道独立分布特征，按张量量化（全局单参数）效率更高，精度满足需求（区别于权重的按通道量化）\n",
      "============================================================\n",
      "\n",
      "按通道量化模型输出:\n",
      "tensor([[0.1640, 0.2343]])\n",
      "\n",
      "量化误差（L2范数）: 0.005609\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.ao import quantization\n",
    "\n",
    "# 1. 定义待量化模型（含量化/反量化节点）\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = quantization.QuantStub()  # 输入FP32→INT8\n",
    "        self.dequant = quantization.DeQuantStub()  # 输出INT8→FP32\n",
    "        \n",
    "        self.linear1 = nn.Linear(3, 4, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(4, 2, bias=False)\n",
    "        \n",
    "        # 固定权重，便于观察量化效果\n",
    "        self.linear1.weight.data = torch.tensor(\n",
    "            [[0.1234, 0.5678, 0.9012],\n",
    "             [-0.2468, -0.1357, 0.3579],\n",
    "             [0.4680, 0.7890, -0.1011],\n",
    "             [-0.3234, 0.6543, -0.9876]],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        self.linear2.weight.data = torch.tensor(\n",
    "            [[0.1122, -0.3344, 0.5566, -0.7788],\n",
    "             [0.2233, -0.4455, 0.6677, -0.8899]],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "# 2. 初始化浮点模型，获取基准输出\n",
    "model_fp32 = SimpleModel()\n",
    "model_fp32.eval()  # 量化仅支持eval模式\n",
    "torch.manual_seed(42)  # 固定种子，结果可复现\n",
    "test_input = torch.randn(1, 3)\n",
    "output_fp32 = model_fp32(test_input)\n",
    "print(f\"浮点模型输出:\\n{output_fp32}\\n\")\n",
    "\n",
    "# 3. 量化核心步骤（权重按通道，激活按张量）\n",
    "# 3.1 配置量化规则：fbgemm默认权重按通道量化，激活按张量量化\n",
    "qconfig = quantization.get_default_qconfig(\"fbgemm\")\n",
    "model_fp32.qconfig = qconfig\n",
    "\n",
    "# 3.2 准备校准：插入假量化节点，开启统计\n",
    "model_prepared = quantization.prepare(model_fp32)\n",
    "\n",
    "# 3.3 激活校准：统计激活分布（模拟10个样本）\n",
    "calibration_data = [torch.randn(1, 3) for _ in range(10)]\n",
    "with torch.no_grad():\n",
    "    for data in calibration_data:\n",
    "        model_prepared(data)\n",
    "\n",
    "# 3.4 转换为INT8模型：权重按通道量化，激活按张量量化\n",
    "model_int8 = quantization.convert(model_prepared)\n",
    "model_int8.eval()\n",
    "\n",
    "# 4. 量化参数分析\n",
    "print(\"=\"*60)\n",
    "# linear1权重（按通道量化：每个输出通道独立scale/zero_point）\n",
    "quantized_linear1 = model_int8.linear1\n",
    "quantized_weight1 = quantized_linear1.weight()\n",
    "\n",
    "print(f\"linear1 原始FP32权重:\\n{model_fp32.linear1.weight.data}\")\n",
    "print(f\"\\nlinear1 按通道量化INT8权重:\\n{quantized_weight1.int_repr()}\")\n",
    "print(f\"\\nlinear1 反量化FP32权重:\\n{quantized_weight1.dequantize()}\")\n",
    "\n",
    "# 按通道量化参数\n",
    "scales = quantized_weight1.q_per_channel_scales()\n",
    "zero_points = quantized_weight1.q_per_channel_zero_points()\n",
    "axis = quantized_weight1.q_per_channel_axis()\n",
    "print(f\"\\nlinear1 按通道量化参数（{len(scales)}个通道）:\")\n",
    "for i in range(len(scales)):\n",
    "    print(f\"  通道{i} - scale: {scales[i].item():.6f}, zero_point: {zero_points[i].item()}\")\n",
    "print(f\"  通道维度: axis={axis}（0=输出特征维度）\")\n",
    "\n",
    "# 激活量化参数（按张量量化：全激活张量共用1套scale/zero_point，无多通道独立分布特征，效率更高且精度足够）\n",
    "quant_stub = model_int8.quant\n",
    "act_scale = quant_stub.scale.item()\n",
    "act_zero_point = quant_stub.zero_point.item()\n",
    "print(f\"\\n激活量化参数（按张量） - scale: {act_scale:.6f}, zero_point: {act_zero_point}\")\n",
    "print(\"  说明：激活无多通道独立分布特征，按张量量化（全局单参数）效率更高，精度满足需求（区别于权重的按通道量化）\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 5. 推理与误差对比\n",
    "output_int8 = model_int8(test_input)\n",
    "print(f\"\\n按通道量化模型输出:\\n{output_int8}\")\n",
    "quant_error = torch.norm(output_fp32 - output_int8).item()\n",
    "print(f\"\\n量化误差（L2范数）: {quant_error:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235917fd-9ad4-4b82-8205-88c8a1b47cfb",
   "metadata": {},
   "source": [
    "### 量化感知训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ab315d-b0fa-41e8-8d97-4f674555807f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始量化感知训练（QAT）...\n",
      "Epoch 1, 平均损失: 0.537143\n",
      "Epoch 2, 平均损失: 0.536015\n",
      "Epoch 3, 平均损失: 0.536302\n",
      "\n",
      "============================================================\n",
      "linear1 按通道量化INT8权重:\n",
      "tensor([[  18,   80,  127],\n",
      "        [ -86,  -48,  127],\n",
      "        [  76,  127,  -18],\n",
      "        [ -42,   84, -128]], dtype=torch.int8)\n",
      "\n",
      "linear1 按通道量化参数（4个通道）:\n",
      "  通道0 - scale: 0.007069, zero_point: 0\n",
      "  通道1 - scale: 0.002813, zero_point: 0\n",
      "  通道2 - scale: 0.006188, zero_point: 0\n",
      "  通道3 - scale: 0.007746, zero_point: 0\n",
      "\n",
      "激活量化参数（按张量） - scale: 0.003848, zero_point: 0\n",
      "============================================================\n",
      "\n",
      "训练前浮点模型输出:\n",
      "tensor([[-0.1679, -0.1966]], grad_fn=<MmBackward0>)\n",
      "QAT量化模型输出:\n",
      "tensor([[0.0000, 0.0279]])\n",
      "QAT量化误差（L2范数）: 0.280334\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.ao import quantization\n",
    "\n",
    "# 1. 定义待量化模型（含量化/反量化节点）\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = quantization.QuantStub()  # 输入FP32→INT8\n",
    "        self.dequant = quantization.DeQuantStub()  # 输出INT8→FP32\n",
    "        \n",
    "        self.linear1 = nn.Linear(3, 4, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(4, 2, bias=False)\n",
    "        \n",
    "        # 固定初始权重，便于观察QAT效果\n",
    "        self.linear1.weight.data = torch.tensor(\n",
    "            [[0.1234, 0.5678, 0.9012],\n",
    "             [-0.2468, -0.1357, 0.3579],\n",
    "             [0.4680, 0.7890, -0.1011],\n",
    "             [-0.3234, 0.6543, -0.9876]],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        self.linear2.weight.data = torch.tensor(\n",
    "            [[0.1122, -0.3344, 0.5566, -0.7788],\n",
    "             [0.2233, -0.4455, 0.6677, -0.8899]],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "# 2. 初始化模型 + 配置QAT量化规则\n",
    "model = SimpleModel()\n",
    "# QAT专用qconfig：训练时模拟量化误差，fbgemm适配x86，权重按通道、激活按张量\n",
    "qconfig = quantization.get_default_qat_qconfig(\"fbgemm\")\n",
    "model.qconfig = qconfig\n",
    "\n",
    "# 3. 准备量化感知训练（QAT）模型（核心：插入量化模拟节点，训练时感知量化误差）\n",
    "model_prepared = quantization.prepare_qat(model)\n",
    "model_prepared.train()  # QAT需要在训练模式下执行\n",
    "\n",
    "# 4. 简单的训练循环（新手演示用，仅3轮训练）\n",
    "optimizer = torch.optim.SGD(model_prepared.parameters(), lr=0.01)  # 优化器\n",
    "loss_fn = nn.MSELoss()  # 损失函数（回归任务）\n",
    "torch.manual_seed(42)   # 固定种子，结果可复现\n",
    "\n",
    "# 模拟训练数据：10个样本，输入3维，标签2维（和模型输出匹配）\n",
    "train_data = [torch.randn(1, 3) for _ in range(10)]\n",
    "train_labels = [torch.randn(1, 2) for _ in range(10)]\n",
    "\n",
    "# 训练循环（QAT核心：训练过程中让模型适应量化误差）\n",
    "print(\"开始量化感知训练（QAT）...\")\n",
    "for epoch in range(3):\n",
    "    total_loss = 0.0\n",
    "    for x, y in zip(train_data, train_labels):\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        output = model_prepared(x)  # 前向传播（含量化模拟）\n",
    "        loss = loss_fn(output, y)   # 计算损失\n",
    "        loss.backward()             # 反向传播\n",
    "        optimizer.step()            # 更新权重\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, 平均损失: {total_loss/len(train_data):.6f}\")\n",
    "\n",
    "# 5. 训练完成后，转换为真正的INT8量化模型\n",
    "model_prepared.eval()  # 转换前切回推理模式\n",
    "model_int8 = quantization.convert(model_prepared)\n",
    "\n",
    "# 6. 测试量化模型效果\n",
    "test_input = torch.randn(1, 3)\n",
    "# 原始浮点模型（训练前）输出对比\n",
    "model.eval()\n",
    "output_fp32 = model(test_input)\n",
    "# QAT量化模型输出\n",
    "output_int8 = model_int8(test_input)\n",
    "\n",
    "# 7. 量化参数分析\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "# linear1权重（按通道量化）\n",
    "quantized_linear1 = model_int8.linear1\n",
    "quantized_weight1 = quantized_linear1.weight()\n",
    "\n",
    "print(f\"linear1 按通道量化INT8权重:\\n{quantized_weight1.int_repr()}\")\n",
    "# 按通道量化参数\n",
    "scales = quantized_weight1.q_per_channel_scales()\n",
    "zero_points = quantized_weight1.q_per_channel_zero_points()\n",
    "print(f\"\\nlinear1 按通道量化参数（{len(scales)}个通道）:\")\n",
    "for i in range(len(scales)):\n",
    "    print(f\"  通道{i} - scale: {scales[i].item():.6f}, zero_point: {zero_points[i].item()}\")\n",
    "\n",
    "# 激活量化参数（按张量：全激活张量共用1套scale/zero_point，无多通道独立分布特征，效率更高且精度足够）\n",
    "quant_stub = model_int8.quant\n",
    "act_scale = quant_stub.scale.item()\n",
    "act_zero_point = quant_stub.zero_point.item()\n",
    "print(f\"\\n激活量化参数（按张量） - scale: {act_scale:.6f}, zero_point: {act_zero_point}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 8. 结果对比\n",
    "print(f\"\\n训练前浮点模型输出:\\n{output_fp32}\")\n",
    "print(f\"QAT量化模型输出:\\n{output_int8}\")\n",
    "# 计算量化误差\n",
    "quant_error = torch.norm(output_fp32 - output_int8).item()\n",
    "print(f\"QAT量化误差（L2范数）: {quant_error:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (quantization)",
   "language": "python",
   "name": "quantization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
